{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.datasets\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation Algorithm From Scratch\n",
    "\n",
    "The idea is to implement the **Back Propagation** algorithm to train Feed Forward Neural Networks. \n",
    "\n",
    "We will implement the algorithm from scratch in Python, and we will only use built-in libraries and numpy, avoiding for the moment the usage of higher-level frameworks (Pytorch or Tensorflow).\n",
    "\n",
    "This excersice will help me remeber the foundations of Deep Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "The **Loss Function** for the moment is the $l_2$ norm of the difference between the predicted and true labels ($\\hat y$ and $y$, respecitvely).\n",
    "\n",
    "$$\n",
    "L(y, \\hat y) = \\dfrac{1}{2}\\|y-\\hat y \\|^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    N_points = y_true.shape[0]\n",
    "    return (1.0/(2.0*N_points))*np.linalg.norm(y_true-y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward Model\n",
    "\n",
    "The **Feed Forward** model considers the consecutive application of linear transformations and activation functions. Given an input $x$, the model's output is given by:\n",
    "\n",
    "$$\n",
    "g(x) = f_K(f_{K-1}(\\cdots f_2(f_1(x))))\n",
    "$$\n",
    "\n",
    "where:\n",
    "$$\n",
    "\\\\\n",
    "f_0 = x,  \\\\\n",
    "f_i = \\sigma(A_{i-1}f_{i-1}+b_{i-1})\n",
    "$$\n",
    "\n",
    "\n",
    "For simplicity, we consider the activation functions to be the sigmoid function:\n",
    "\n",
    "$$\n",
    "\\sigma (x) = \\dfrac{1}{1+e^{-x}},  \\\\\n",
    "\\sigma ' (x) = \\sigma (x) (1-\\sigma (x))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Learning using Gradient Descent\n",
    "\n",
    "\n",
    "Notice that the model $g(x)$ depends on the parameters $\\{A_0, b_0, \\cdots, A_{K-1}, b_{K-1}\\}$ that represent the weights ($A_i$) and the biases ($b_i$) of the model. Such parameters are optimized using a Gradient Descent algorithm, which updates the values of the parameters iteratively by following the rule:\n",
    "\n",
    "\n",
    "$$\n",
    "A_i \\leftarrow A_i - \\alpha \\dfrac{\\partial L}{\\partial A_i} \\\\\n",
    "b_i \\leftarrow b_i - \\alpha \\dfrac{\\partial L}{\\partial b_i}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the learning rate.\n",
    "\n",
    "\n",
    "Hence, the question is: How do we estimate $\\dfrac{\\partial L}{\\partial A_i}$? The answer is the Backpropagation algorithm, which in turn is based on a reverse application of the Chain Rule for diferentiation.\n",
    "\n",
    "### Chain Rule\n",
    "\n",
    "\n",
    "Consider the model for $g(x)$ by using the following auxiliary variables:\n",
    "\n",
    "$$\n",
    "h_i = A_{i-1}f_{i-1}+b_{i-1} \\\\\n",
    "f_i = \\sigma (h_i)\n",
    "$$\n",
    "\n",
    "where the boundary conditions is $f_0 = x$.\n",
    "\n",
    "The Chain Rule states:\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial L}{\\partial A_{K-1}} = \\dfrac{\\partial L}{\\partial f_K} \\dfrac{\\partial f_K}{\\partial h_K} \\dfrac{\\partial h_K}{\\partial A_{K-1}} \\\\\n",
    "\\dfrac{\\partial L}{\\partial A_{K-2}} = \\dfrac{\\partial L}{\\partial f_K} (\\dfrac{\\partial f_K}{\\partial h_K} \\dfrac{\\partial h_K}{\\partial f_{K-1}} ) (\\dfrac{\\partial f_{K-1}}{\\partial h_{K-1}} \\dfrac{\\partial h_{K-1}}{\\partial A_{K-2}} )\\\\\n",
    "\\dfrac{\\partial L}{\\partial A_{K-3}} = \\dfrac{\\partial L}{\\partial f_K} (\\dfrac{\\partial f_K}{\\partial h_K} \\dfrac{\\partial h_K}{\\partial f_{K-1}} ) (\\dfrac{\\partial f_{K-1}}{\\partial h_{K-1}} \\dfrac{\\partial h_{K-1}}{\\partial f_{K-2}} ) (\\dfrac{\\partial f_{K-2}}{\\partial h_{K-2}} \\dfrac{\\partial h_{K-2}}{\\partial A_{K-3}} )\\\\\n",
    "\\dfrac{\\partial L}{\\partial A_{i}} = \\dfrac{\\partial L}{\\partial f_K} (\\dfrac{\\partial f_K}{\\partial h_K} \\dfrac{\\partial h_K}{\\partial f_{K-1}} ) (\\dfrac{\\partial f_{K-1}}{\\partial h_{K-1}} \\dfrac{\\partial h_{K-1}}{\\partial f_{K-2}} )\\cdots(\\dfrac{\\partial f_{i+2}}{\\partial h_{i+1}} \\dfrac{\\partial h_{i+1}}{\\partial f_{i+1} }) (\\dfrac{\\partial f_{i+1}}{\\partial h_{i+1}} \\dfrac{\\partial h_{i+1}}{\\partial A_{i} })\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "Some of the terms are:\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial L}{\\partial f_K}  = \\dfrac{\\partial }{\\partial f_K} \\| y-f_K\\|^2 = -2 (y-f_k)I \\\\\n",
    "\\dfrac{\\partial f_i}{\\partial h_i} = \\sigma (h_i) (1-\\sigma (h_i)) \\\\\n",
    "\\dfrac{\\partial h_i}{\\partial f_{i-1}} = A_{i-1} \\\\\n",
    "\\dfrac{\\partial h_i}{\\partial A_{i-1}} = f_i \\otimes I\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Model - 2 hidden layers\n",
    "\n",
    "In a 2 hidden layer model, the computational graph will be as follows:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    " x & \\rightarrow & z_1 =w_1x+b_1 \\\\\n",
    "     & \\rightarrow & h_1 = \\sigma (z_1) \\\\\n",
    "     & \\rightarrow & z_2 = w_2 h_1+ b_2 \\\\\n",
    "     & \\rightarrow & h_2 = \\sigma (z_2)\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sklearn.datasets.load_boston(return_X_y=True)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'W1' : np.random.rand(hidden_dim, input_dim),\n",
    "    'W2' : np.random.rand(hidden_dim),\n",
    "    'b1' : np.random.rand(hidden_dim),\n",
    "    'b2' : np.random.rand()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, weights):\n",
    "    z1 = np.dot(X, weights['W1'].T)+weights['b1']\n",
    "    h1 = sigmoid(z1)\n",
    "    z2 = np.dot(h1, weights['W2'].T)+weights['b2']\n",
    "    h2 = sigmoid(z2)\n",
    "    return z1, h1, z2, h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1, h1, z2, h2 = forward_prop(X, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain rule\n",
    "\n",
    "For the $w_2$ parameter, the chain rule is:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\dfrac{\\partial L}{\\partial w_2} & = & \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial w_2}  \\\\\n",
    "                                & = &  \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial z_2} \\dfrac{\\partial z_2}{\\partial w_2}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "For the $w_1$:\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\dfrac{\\partial L}{\\partial w_1} & = & \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial w_1}  \\\\\n",
    "                                & = &  \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial z_2} \\dfrac{\\partial z_2}{\\partial w_1}\\\\ \n",
    "                                & = &  \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial z_2} \\dfrac{\\partial z_2}{\\partial h_1} \\dfrac{\\partial h_1}{\\partial w_1}\\\\ \n",
    "                                & = &  \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial z_2} \\dfrac{\\partial z_2}{\\partial h_1} \\dfrac{\\partial h_1}{\\partial z_1} \\dfrac{\\partial z_1}{\\partial w_1}\\\\ \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "Notice that the calculations of $\\dfrac{\\partial L}{\\partial w_2}$ and $\\dfrac{\\partial L}{\\partial w_1}$ reuse some terms, and so we can reduce computation.\n",
    "The same is true for the bias parameters $b_2$ and $b_1$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\dfrac{\\partial L}{\\partial b_2} & = & \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial b_2}  \\\\\n",
    "                                & = &  \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial z_2} \\dfrac{\\partial z_2}{\\partial b_2}\n",
    "\\end{array}\n",
    "$$\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\dfrac{\\partial L}{\\partial b_1} & = & \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial b_1}  \\\\\n",
    "                                & = &  \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial z_2} \\dfrac{\\partial z_2}{\\partial b_1}\\\\ \n",
    "                                & = &  \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial z_2} \\dfrac{\\partial z_2}{\\partial h_1} \\dfrac{\\partial h_1}{\\partial b_1}\\\\ \n",
    "                                & = &  \\dfrac{\\partial L}{ \\partial h_2} \\dfrac{\\partial h_2}{\\partial z_2} \\dfrac{\\partial z_2}{\\partial h_1} \\dfrac{\\partial h_1}{\\partial z_1} \\dfrac{\\partial z_1}{\\partial b_1}\\\\ \n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(X, y, weights):\n",
    "    N_points = X.shape[0]\n",
    "    z1, h1, z2, h2 = forward_prop(X, weights)\n",
    "    \n",
    "    L = loss(y_true=y, y_pred=h2)\n",
    "    \n",
    "    # Back Propagation\n",
    "    \n",
    "    dLdY = (-2/N_points)*(y-h2).T\n",
    "    dLdZ2 = np.multiply(dLdY, sigmoid_derivative(z2))\n",
    "    dLdW2 = np.dot(h1.T, dLdZ2)\n",
    "    dLdB2 = np.dot(dLdZ2, np.ones(N_points))\n",
    "    \n",
    "    dLdH = np.dot(dLdZ2.reshape(N_points, 1), weights['W2'].reshape(1, -1))\n",
    "    dLdZ1 = np.multiply(dLdH, np.multiply(sigmoid(z1), (1.0-sigmoid(z1))))\n",
    "    dLdW1 = np.dot(dLdZ1.T, X)\n",
    "    dLdB1 = np.dot(dLdZ1.T, np.ones(N_points))\n",
    "    \n",
    "    gradients = {\n",
    "        'W1' : dLdW1,\n",
    "        'b1' : dLdB1,\n",
    "        'W2' : dLdW2,\n",
    "        'b2' : dLdB2\n",
    "    }\n",
    "    \n",
    "    return gradients, L\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'W1': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  'b1': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  'W2': array([-0.000445, -0.000445, -0.000445, -0.000445, -0.000445, -0.000445,\n",
       "         -0.000445, -0.000445, -0.000445, -0.000445]),\n",
       "  'b2': -0.0004450001715725762},\n",
       " 0.520376189058052)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_prop(X, y, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    \n",
    "    epsilon = 0.001\n",
    "    initial_weights = copy.deepcopy(weights)\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch % 5000 ==0:\n",
    "            print(f'Epoch {epoch+1}')\n",
    "        gradients, L = backward_prop(X, y, initial_weights)\n",
    "        for weight_name in weights:\n",
    "            initial_weights[weight_name] -= epsilon * gradients[weight_name]\n",
    "        \n",
    "        losses.append(L)\n",
    "    plt.scatter(range(num_epochs), losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    return losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 5001\n",
      "Epoch 10001\n",
      "Epoch 15001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = train(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
